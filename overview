 1 Introduction
	- inspiration: the original paper
		- it has been inspired by paper xxx for computing axx it has good computations in computer vision, however in order to solve the problem we need all the pieces of knn for the kdtree
 		  it is non-trivial so therefore we decided to concentrate on that. 
 	- how has the project changed direction
	- why is this project useful: knn is core of many applications in various fields such as computer vision, ML
	- high level: that is computing knn with kd trees, internal node semantically corresponds to subset of , and how we reason about whether to visit the next node. 
 	- so what is a k-d tree: to construct - each internal node represents a range of the reference points, and I do not have to compare each query with each reference point. 
	- what does the project contain (concentrate on exact KNN by KD trees, the original has a nice motivation to compute the exact knn by kdtree efficiently)
	- we changed the Implementation uses a slightly different approach in which we use multiple points in each node, rather than just one point. 
	- discuss the difficulties: this reduces the performance to n log n, how efficient it is depends on dim and k. 

	- summarise the conclusion : mention so called dimensionality curse - octal trees cannot do high dim - kd tree can in principal, in practise 2 main problems that may affect: the dimensionality is too high then we might have to visit most reference point and similarly if k is too high and the distance to the worst neighbour becomes to big then we visit more points. before all that introduce that the leaves contain a set of points and we apply brute on the leaf level, because it is still fast when the number of points are small - in the hundred.  
	- how do I address dimensionality curse? - we propose an efficient way to look at higher dimensionality than the original approach. the distance to the current median to the distance of the worst neighbour - now we consider the upper and lower bounds of all dimensions. Improving temporal locality by sorting the leaves by accessing the same reference points in the same order. 
	- a summary of the results: for this dimensionality we obtain these amazing speed-ups and for these k's and how this affects the speed-up etc. - purpose is to demonstrate that these things you have just said are in fact true - give a magical feel. - over 5 I see the performance reduces drastically ... 
	- what are the downsides of the solution - significant overhead and uses contains much more data - so that is why experiments are important to show which ds and ks run best. 
	- how is the report organised

	1.1 Acknowledgement


2 Background
	- the algorithms as pseudo-code
	- why Futhark: supports regular parallelism - which is why it doesnt have recursion, 
	- note on PCA and going on with an approximate solution

	2.1 RelatedWork
		2.1.1 PatchMatch
		2.1.2 Coherency Sensitive Hashing


3 Implementation
	- for each have a difficulties / shortcomings section
	- include nice code of 

	3.1 The Brute Force Version
		- describing which parts are parallel and which are not - and why

	3.2 k-d Tree Construction
		- essential thing: padding technique that allows regular parallelism that is much faster than - the proposed solution uses at least one more - it accounts to less than 1% overhead - so it is totally reafible - it allows to build on top of regular parallelism.
		-
		- batch sorting is a detail - shortcomings in compiler - it was not possible to have the sorting inside the map
		- explaining the sorting solution
		- reasoning about choices w.r.t sorting over partition
			- and why are there three inner maps in the for-loop (due to sorting)
		- not fusing the reduce because then Futhark will fuse them inside. 
		- what is needed to compute so we get a more accurate result

	3.3 Tree Traversal
		- explaining the solution to use a stack 
		- showing a figure of the first traversal: first go to the leaf in which the query naturally belongs 
		- showing (2-3) figures of the continuous traversal with a stack

		3.3.1 Representing the Stack as an Integer
			- including an equation that shows the bit arithmetic of setVisited

		3.3.2 Validating Whether to Look at the `second`
			- reasoning about the original median check
			- showing and reasoning about Cosmin's equation
			- comparing the two
				- benefits, trade-offs

	3.4 The Full Implementation
		- explain how things are put together - main function
		- reason about sorting the queries by the leaves - why is it faster?


4 Experimental Evaluation
	Q: how should the various data sizes, k's and dimension be demonstrated? table/plot

	always test with the best version (sorting and all dimensions)

	4.1 Sorting over Partition 
		- plot and reasoning of partition vs. sorting - including sorting the queries after the leaves

	4.2 Including all Dimensions in the Traversal
		- plot and reasoning of traverse with one median check vs. traverse checking all medians
		- show the `visited` of both solutions as a histogram
	
	4.3 Brute Force versus the k-d Tree
		- plot and reasoning of brute force vs. the best k-d tree

	- Reasoning that an increased number of points will give a higher speed-up





5 Conclusion





