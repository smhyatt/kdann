II. Problem statement:

Given two images A and B, in which each point is 3-channel color (hence 3 dims/ints), 
we decompose them to say 5x5 patches. One can now see the images as a matrix of patches
in a 75-dimension space, i.e., a patch has 5x5x3 components.

The problem at hand is to find for each patch from image A its approximate nearest
neighbor in image B.   The difficulty is that since the images are big, searching
for the nearest neighbor in a brute-force way---by comparing each patch in A with
each patch in B---is too expensive.

Abbreviations: 
ANN = approximate nearest neighbor
NN  = nearest neighbor

III. Main Steps of the Target Approximate Algorithm

see "Computing Nearest-Neighbor Fields via Propagation Assisted KD-Trees", He and Sun.

1. Choose a fix number of dimensions (say 20), and pick a number (say 1000) of random 
    patches from the images and perform Principal Component Analysis (PCA), i.e., pick the
    most important 20 dimensions and get rid of the rest (reduce dimensionality).

2. Build a KD-tree for the patches in B: at each recursive step,
       we chose and split the space by the median value (of the set to be split).
       The median split results in a balanced tree. The recursion continues until
       each leaf (but the last one) contains a statically chosen `m` patches (say 50). 
        

3. Approximate search through the KD-tree:

 a) Find an exact NN solution for the first row of patches in A, by fully
        propagating through the KD tree and performing a brute-force search
        at each leaf that is encountered.

 b) For the remaining patches perform an approximate KD-tree search (cheaper), 
        in which only the first leaf encountered is searched, i.e., no backtracking,
        much simpler implementation.
      This is further subdivided in two steps:
        i) propagate through the KD-tree and find the index of the first encountered
            leaf;
       ii) perform brute-force search with the patches contained by that leaf. 

4. Propagation Step: note that the NN for the patches of the first row are highly
     accuracy (exact). We can use them to improve the accuracy of the other by a
     sequential-propagation procedure which updates each patch in row `i` in the
     following way: 
        a) lookup the leaf `l_{i-1}` of the top neighbor (i.e., row `i-1` computed 
            in previous time step)
        b) perform a brute force w.r.t. that leaf (`l_{i-1}`), and chose the best
            between the resulted ANN and the current result (from step III).

     This step basically uses something akin to the "locality" principle, and
        reportedly works well in practice. 

IV. Source code is in file `cpu.py`

  0. download sources from: 
        http://www.fabiangieseke.de/data/cosmin_annfield.zip

  1. Installation:
     $ virtualenv -p python3 annfield
     $ source annfield/bin/activate # activates environment
     $ pip install -r requirements.txt
     $ python cpu.py

  2. Code description:
    lines 19-20 reading the images
    lines 29-30 reshaping images in a 1d array of patches 
        (of dimension `psize*psize*n_channels`)
    lines 33-34: picking 1000 random patches from images A and B
    lines 39-41: perform PCA on the random patches to find the
        `pca_dim` most important dimensions.
    lines 44-45: apply the PCA model to all patches in the images A and B,
        i.e., keep only the important dimensions from each patch; 
        per-patch dimensionality is now reduced to `pca_dim`

    line 51-57: corresponds to the baseline (expensive) implementation, which
        - constructs the KD-Tree w.r.t. the reduced patches of B
        - applies the full KD-Tree propagation for the reduced patches of A,
            i.e., with backtracking.
        
    lines 64 - onwards: implements the propagated version
        - line 69: builds the KD tree from the reduced patches of B;
                    the implementation of `build_kd_tree` is in util.py
        - loop `for patch_y in range(n_rows):` is sequentially propagating
            across successive rows
        - loop `for patch_x in range(n_cols):` is semantically parallel,
            i.e., forall patch_x in a row do:
        -  line 97: calls `traverse_tree`, also implemented in `util.py`
            (i) the second parameter tells whether it should use the full
                    traversal with backtracking (for the first row, see III.3.a),
                    or the cheaper traversal that starts at the first encountered 
                    leaf (see III.3.b)
           (ii) currently `traverse_tree` also applies the brute-force search
                algorithm on the leaves.

        - line 98: `propagate_patches` does the propagation (III.4);
        
        - Please note that the code is ugly written in that it performs
            all steps III.3 (a,b) and III.4 in one iteration of the loop,
            rather than as described in my algorithm.
            (they promised to re-write it ...)

V. How do we approach it?

We pragmatically start to parallelize what takes the longest time to execute,
and then we move to the next computational bottleneck and so on. We can use
Futhark for implementation and its python code generator, with which we can
easily translates parts of the program to Futhark and link them back in the
original program.

The computational bottleneck are steps III.3.b and III.4. We can start parallelizing
there. For example we will probably start with III.3.b: we get the input and the 
result by running and printing from the python program, then make a reference 
input/result for Futhark and then start translating step III.3.b to Futhark,
until it validates. However, note that Futhark does not support recursive call,
so we will need to rewrite the recursive calls as a loop, which is relatively 
straightforward for III.3.b (but tricky for III.3.a).
 
Of course, ideally all the steps will be translated to GPU, but we are
time constrained, so we will address this pragmatically.

I think I have overwhelmed you with information; I'll stop here.













